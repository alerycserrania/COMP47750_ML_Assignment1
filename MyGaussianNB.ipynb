{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Gaussian Naive Bayes Classifier\n",
    "\n",
    "The aim of this project is to implement and test a Guassian Naive Bayes classifier."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.naive_bayes import GaussianNB\r\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\r\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, classification_report, ConfusionMatrixDisplay\r\n",
    "from sklearn.model_selection import cross_val_score\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import timeit\r\n",
    "\r\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GaussianNB Classifier\n",
    "An implementation of a Gaussian Naive Bayes that fits the framework."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class MyGaussianNB(BaseEstimator, ClassifierMixin):\r\n",
    "    def fit(self, xt, yt):\r\n",
    "        xt = np.array(xt)\r\n",
    "        yt = np.array(yt)\r\n",
    "\r\n",
    "        # first phase: compute class priors\r\n",
    "        self._classes, self._class_priors = np.unique(yt, return_counts=True)\r\n",
    "        self._class_priors = self._class_priors / float(np.sum(self._class_priors))  \r\n",
    "\r\n",
    "        # second phase: compute all features' means and variances\r\n",
    "        xt_split = [xt[yt==cl] for cl in self._classes]\r\n",
    "        self._means = np.array([np.mean(xtcl, axis=0) for xtcl in xt_split])\r\n",
    "        self._vars = np.array([np.var(xtcl, axis=0) for xtcl in xt_split])\r\n",
    "        return self\r\n",
    "\r\n",
    "    def predict(self, xtests):\r\n",
    "        xtests = np.array(xtests)\r\n",
    "\r\n",
    "        probas = self._compute_probas(xtests)\r\n",
    "        return np.array([self._classes[i] for i in np.argmax(probas, axis=0)])\r\n",
    "\r\n",
    "    def _compute_probas(self, xtests):\r\n",
    "        return np.array([\r\n",
    "            [\r\n",
    "                self._class_priors[i] * np.product(self._conditional_proba(xtest, self._means[i], self._vars[i])) \r\n",
    "                for xtest in xtests\r\n",
    "            ]\r\n",
    "            for i in range(np.size(self._classes))\r\n",
    "        ])\r\n",
    "    \r\n",
    "    @staticmethod\r\n",
    "    def _conditional_proba(xt, m, var):\r\n",
    "        return np.exp(-np.power(xt-m, 2)/(2*var))/np.sqrt(2*np.pi*var)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The function below will compare Scikit Gaussian NB and my implementation of Gaussian NB using accuracy and ROC analysis."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def test_gaussian_on_dataset(x_train, y_train, x_test, y_test):\r\n",
    "    X = np.concatenate((x_train, x_test))\r\n",
    "    y = np.concatenate((y_train, y_test))\r\n",
    "    gnb = GaussianNB()\r\n",
    "    gnb.fit(x_train, y_train)\r\n",
    "    y_pred = gnb.predict(x_test)\r\n",
    "    cm = confusion_matrix(y_test, y_pred)\r\n",
    "    report = classification_report(y_test, y_pred, target_names=['Not Helpful', 'Helpful'])\r\n",
    "    disp = ConfusionMatrixDisplay(cm)\r\n",
    "    fig, ax = plt.subplots(figsize=(3,3))\r\n",
    "    ax.set_title(\"Scikit GNB Confusion Matrix\")\r\n",
    "    disp.plot(ax=ax)\r\n",
    "\r\n",
    "    print(f\"Scikit GNB - Report:\\n{report}\")\r\n",
    "    print(f\"Scikit GNB - Accuracy:\\t{accuracy_score(y_test, y_pred)}\")\r\n",
    "    print(f\"Scikit GNB - F1 Score:\\t{f1_score(y_test, y_pred)}\")\r\n",
    "    print(f\"Scikit GNB - 5x CV Accuracy:\\t{cross_val_score(gnb, X, y).mean()}\")\r\n",
    "    print(f\"Scikit GNB - 5x CV F1 Score:\\t{cross_val_score(gnb, X, y, scoring='f1', error_score='raise').mean()}\")\r\n",
    "    print(f\"Scikit GNB - 5x CV Precision:\\t{cross_val_score(gnb, X, y, scoring='precision').mean()}\")\r\n",
    "    print(f\"Scikit GNB - 5x CV Recall:\\t{cross_val_score(gnb, X, y, scoring='recall').mean()}\")\r\n",
    "\r\n",
    "    print()\r\n",
    "    \r\n",
    "    mgnb = MyGaussianNB()\r\n",
    "    mgnb.fit(x_train,y_train)\r\n",
    "    y_pred = mgnb.predict(x_test)\r\n",
    "    cm = confusion_matrix(y_test, y_pred)\r\n",
    "    report = classification_report(y_test, y_pred, target_names=['Not Helpful', 'Helpful'])\r\n",
    "    disp = ConfusionMatrixDisplay(cm)\r\n",
    "    fig, ax = plt.subplots(figsize=(3,3))\r\n",
    "    ax.set_title(\"My GNB Confusion Matrix\")\r\n",
    "    disp.plot(ax=ax)\r\n",
    "\r\n",
    "    print(f\"My GNB - Report:\\n{report}\")\r\n",
    "    print(f\"My GNB - Accuracy:\\t{accuracy_score(y_test, y_pred)}\")\r\n",
    "    print(f\"My GNB - F1 Score:\\t{f1_score(y_test, y_pred)}\")\r\n",
    "    print(f\"My GNB - 5x CV Accuracy:\\t{cross_val_score(mgnb, X, y).mean()}\")\r\n",
    "    print(f\"My GNB - 5x CV F1 Score:\\t{cross_val_score(mgnb, X, y, scoring='f1').mean()}\")\r\n",
    "    print(f\"My GNB - 5x CV Precision:\\t{cross_val_score(mgnb, X, y, scoring='precision').mean()}\")\r\n",
    "    print(f\"My GNB - 5x CV Recall:\\t{cross_val_score(mgnb, X, y, scoring='recall').mean()}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This function below will compare Scikit's Gaussian NB and mine in terms of speed."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def test_speed_on_dataset(x_train, y_train, x_test, y_test, repeat=100):\r\n",
    "    gnb = GaussianNB()\r\n",
    "    gnb_fit_time = timeit.timeit(lambda: gnb.fit(x_train, y_train), number=repeat)\r\n",
    "    gnb_predict_time = timeit.timeit(lambda: gnb.predict(x_test), number=repeat)\r\n",
    "    \r\n",
    "    print(f'Scikit GNB fit performance: {gnb_fit_time}s ({repeat} times)')\r\n",
    "    print(f'Scikit GNB predict performance: {gnb_predict_time}s ({repeat} times)')\r\n",
    "\r\n",
    "    mgnb = MyGaussianNB()\r\n",
    "    mgnb_fit_time = timeit.timeit(lambda: mgnb.fit(x_train, y_train), number=repeat)\r\n",
    "    mgnb_predict_time = timeit.timeit(lambda: mgnb.predict(x_test), number=repeat)\r\n",
    "\r\n",
    "    print(f'My GNB fit performance: {mgnb_fit_time}s ({repeat} times)')\r\n",
    "    print(f'My GNB predict performance: {mgnb_predict_time}s ({repeat} times)')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Penguins dataset\n",
    "Running and testing Gaussian Naive Bayes on the penguin dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "penguins_af = pd.read_csv('penguins_af.csv', index_col = 0)\r\n",
    "print(penguins_af.shape)\r\n",
    "penguins_af.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "penguins_af['target'] = np.where(penguins_af['species'] == 'Adelie', 1, 0)\r\n",
    "f_names = ['bill_length_mm', 'bill_depth_mm','flipper_length_mm', 'body_mass_g', 'species', 'target']\r\n",
    "penguins = penguins_af[f_names]\r\n",
    "penguins2C = penguins.loc[penguins['species'].isin(['Adelie','Chinstrap'])]\r\n",
    "penguins2C.pop('species')\r\n",
    "penguins2C.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y = penguins2C.pop('target').values\r\n",
    "X_raw = penguins2C.values\r\n",
    "feature_names = penguins2C.columns\r\n",
    "X_tr_raw, X_ts_raw, y_train, y_test = train_test_split(X_raw, y, test_size=1/2)\r\n",
    "scaler = MinMaxScaler()\r\n",
    "X_train = scaler.fit_transform(X_tr_raw)\r\n",
    "X_test = scaler.transform(X_ts_raw)\r\n",
    "X_train.shape, X_test.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_gaussian_on_dataset(X_train, y_train, X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_speed_on_dataset(X_train, y_train, X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Diabetes dataset\n",
    "Running and testing Gaussian Naive Bayes on the diabetes test dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "diabetes = pd.read_csv('diabetes.csv', index_col = 0)\r\n",
    "print(diabetes.shape)\r\n",
    "diabetes.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "diabetes['target'] = np.where(diabetes['neg_pos'] == 'tested_positive', 1, 0)\r\n",
    "diabetes.pop('neg_pos').values\r\n",
    "diabetes.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y = diabetes.pop('target').values\r\n",
    "Xorig = diabetes.values\r\n",
    "scaler = StandardScaler()\r\n",
    "X = scaler.fit_transform(Xorig)\r\n",
    "X.shape, y.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_gaussian_on_dataset(X_train, y_train, X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_speed_on_dataset(X_train, y_train, X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hotel Reviews dataset\n",
    "Running and testing Gaussian Naive Bayes on the helpfulness of hotel reviews dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "reviews = pd.read_csv('HotelRevHelpfulness.csv', index_col=0)\r\n",
    "print(reviews.shape)\r\n",
    "reviews.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y = reviews.pop('reviewHelpfulness').values\r\n",
    "x_raw = reviews.values\r\n",
    "scaler = StandardScaler()\r\n",
    "x = scaler.fit_transform(x_raw)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=1/3)\r\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_gaussian_on_dataset(x_train, y_train, x_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_speed_on_dataset(x_train, y_train, x_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Conclusion"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For binary classification:\r\n",
    "\r\n",
    "- Evaluation: \r\n",
    "\r\n",
    "  - their confusion matrices are equals ;\r\n",
    "  - their accuracies, f1 scores, recall and precisions are equals for the 3 datasets ;\r\n",
    "\r\n",
    "- Speed:\r\n",
    "\r\n",
    "  - `fit` method: Scikit is slower than mine (about 4 times) ;\r\n",
    "  -  `predict` method: Scikit is faster than mine (about 40 times).\r\n",
    "\r\n",
    "- What I suspect for these differences:\r\n",
    "\r\n",
    "  - Scikit may compute other values when fitting the model in order to optimize the predictions ;\r\n",
    "  - Scikit may use a better but equivalent algorithm to compute the conditional probabilities."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "33fa5f6e416b87f8609131718fa65b71d8145a1257be68be3d404c8842433359"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}